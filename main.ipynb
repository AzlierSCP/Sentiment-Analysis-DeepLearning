{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "I am going to design a DNN to complete the sentiment analysis task, using the popular publicly available SST2 datasets, which is a movie review dataset, each sample contains a sentence and the corresponding label of the sentence, 1 means positive and 0 means negative. for this, we need to design a suitable text embedding and DNN, such as RNN/GRU/LSTM, etc., and compare the performances of different models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import pickle\n",
    "import csv\n",
    "from collections import Counter\n",
    "import wget\n",
    "from zipfile import ZipFile\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Text Embedding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_embedding_matrix(vocab):\n",
    "    glove_file_path = \"./data/glove_embeddings/glove.6B.50d.txt\"\n",
    "    embedding_dim = 50\n",
    "\n",
    "    # Create a dictionary to store GloVe embeddings\n",
    "    embeddings = {}\n",
    "\n",
    "    # Read in GloVe embeddings and add them to the dictionary if they are in vocab\n",
    "    with open(glove_file_path, \"r\", encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            token = values[0]\n",
    "            if token in vocab:\n",
    "                embedding = torch.tensor([float(val) for val in values[1:]], dtype=torch.float32)\n",
    "                embeddings[token] = embedding\n",
    "\n",
    "    # Create a tensor to store all embeddings in the dictionary\n",
    "    all_embeddings = torch.stack(list(embeddings.values()), dim=0)\n",
    "\n",
    "    # Compute the mean and standard deviation of all embeddings\n",
    "    embedding_mean = torch.mean(all_embeddings)\n",
    "    embedding_std = torch.std(all_embeddings)\n",
    "\n",
    "    # Randomly initialize embeddings using the mean and standard deviation\n",
    "    embedding_matrix = torch.normal(embedding_mean, embedding_std, (len(vocab), embedding_dim))\n",
    "\n",
    "    # Replace the randomly initialized embeddings with GloVe embeddings if they exist in vocab\n",
    "    for token, embedding in embeddings.items():\n",
    "        embedding_matrix[vocab[token]] = embedding\n",
    "\n",
    "    # Initialize the padding token to 0\n",
    "    embedding_matrix[vocab[\"[pad]\"]] = 0.\n",
    "\n",
    "    return embedding_matrix\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class SST2Dataset(Dataset):\n",
    "    def __init__(self, path: Path, vocab=None, reverse_vocab=None, is_test=False):\n",
    "        super().__init__()\n",
    "\n",
    "        with open(path, \"r\") as f:\n",
    "            reader = csv.reader(f, delimiter=\"\\t\", quoting=csv.QUOTE_NONE)\n",
    "            next(reader)  # Ignore header\n",
    "            data = list(reader)\n",
    "\n",
    "        sentences = []\n",
    "        labels = []\n",
    "\n",
    "        for row in data:\n",
    "            if not is_test:\n",
    "                # Each row contains a sentence and label (either 0 or 1)\n",
    "                sentence, label = row\n",
    "                sentences.append(sentence.strip().split())\n",
    "                labels.append([int(label)])\n",
    "            else:\n",
    "                _, sentence = row\n",
    "                sentences.append(sentence.strip().split())\n",
    "\n",
    "        self.vocab_file_path = \"./data/SST-2/vocab.pkl\"\n",
    "\n",
    "        # Vocab maps tokens to indices\n",
    "        if vocab is None:\n",
    "            vocab = self._build_vocab(sentences)\n",
    "            reverse_vocab = None\n",
    "\n",
    "        # Reverse vocab maps indices to tokens\n",
    "        if reverse_vocab is None:\n",
    "            reverse_vocab = {index: token for token, index in vocab.items()}\n",
    "\n",
    "        self.vocab = vocab\n",
    "        self.reverse_vocab = reverse_vocab\n",
    "\n",
    "        indexed_sentences = [self.tokens_to_indices(sentence) for sentence in sentences]\n",
    "        if not is_test:\n",
    "            labels = torch.tensor(labels)\n",
    "\n",
    "        self.sentences = indexed_sentences\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.sentences[index], self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def _build_vocab(self, sentences, unk_cutoff=1):\n",
    "        # Load cached vocab if existent\n",
    "        if os.path.exists(self.vocab_file_path):\n",
    "            with open(self.vocab_file_path, \"rb\") as f:\n",
    "                return pickle.load(f)\n",
    "\n",
    "        word_counts = Counter()\n",
    "\n",
    "        # Count unique words (lower case)\n",
    "        for sentence in sentences:\n",
    "            for token in sentence:\n",
    "                word_counts[token.lower()] += 1\n",
    "\n",
    "        # Special tokens: padding, beginning of sentence, end of sentence, and unknown word\n",
    "        vocab = {\"[pad]\": 0, \"[unk]\": 1}\n",
    "        token_id = 2\n",
    "\n",
    "        # Assign a unique id to each word that occurs at least unk_cutoff number of times\n",
    "        for token, count in word_counts.items():\n",
    "            if count >= unk_cutoff:\n",
    "                vocab[token] = token_id\n",
    "                token_id += 1\n",
    "\n",
    "        # Cache vocab\n",
    "        with open(self.vocab_file_path, \"wb\") as f:\n",
    "            pickle.dump(vocab, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        return vocab\n",
    "\n",
    "    def tokens_to_indices(self, tokens):\n",
    "        \"\"\"\n",
    "        Converts tokens to indices.\n",
    "        \"\"\"\n",
    "        indices = []\n",
    "\n",
    "        unk_token = self.vocab[\"[unk]\"]\n",
    "\n",
    "        for token in tokens:\n",
    "            indices.append(self.vocab.get(token.lower(), unk_token))\n",
    "\n",
    "        return torch.tensor(indices)\n",
    "\n",
    "    def indices_to_tokens(self, indices):\n",
    "        \"\"\"\n",
    "        Converts indices to tokens and concatenates them as a string.\n",
    "        \"\"\"\n",
    "        tokens = []\n",
    "\n",
    "        for index in indices:\n",
    "            if torch.is_tensor(index):\n",
    "                index = index.item()\n",
    "            token = self.reverse_vocab.get(index, \"[unk]\")\n",
    "            if token == \"[pad]\":\n",
    "                continue\n",
    "            tokens.append(token)\n",
    "\n",
    "        return \" \".join(tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def collate_fn(\n",
    "    batch: List[Tuple[torch.Tensor, torch.Tensor]]\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Create a batch of data given a list of N sequences and labels. Sequences are stacked into a single tensor\n",
    "    of shape (N, max_sequence_length), where max_sequence_length is the maximum length of any sequence in the\n",
    "    batch. Sequences shorter than this length should be filled up with 0's. Also returns a tensor of shape (N, 1)\n",
    "    containing the label of each sequence.\n",
    "    \"\"\"\n",
    "    sentences, labels = zip(*batch)\n",
    "    # Get the maximum sequence length in all sentences\n",
    "    max_sequence_length = max(len(seq) for seq in sentences)\n",
    "\n",
    "    # Create a tensor to hold the padded sequences and fill it with 0\n",
    "    padded_seqs = torch.zeros((len(batch), max_sequence_length))\n",
    "\n",
    "    # Create a tensor to hold the labels and fill it with 1\n",
    "    ret_labels = torch.ones((len(batch), 1))\n",
    "\n",
    "    # Iterate over the sequences and labels in the batch\n",
    "    for i, (seq, label) in enumerate(batch):\n",
    "        # Copy the sequence data into the padded tensor\n",
    "        padded_seqs[i, :len(seq)] = seq\n",
    "\n",
    "        # Copy the label into the label tensor\n",
    "        ret_labels[i, 0] = label\n",
    "\n",
    "    # Return the padded sequences and labels as a tuple\n",
    "    return padded_seqs, ret_labels\n",
    "\n",
    "\n",
    "class RNNBinaryClassificationModel(nn.Module):\n",
    "    def __init__(self, embedding_matrix: torch.Tensor, rnn_type: str):\n",
    "        \"\"\"Create a model with either RNN, LSTM or GRU layer followed by a linear layer.\n",
    "\n",
    "        Args:\n",
    "            embedding_matrix (torch.Tensor): Weights for embedding layer.\n",
    "                Used in starter code, nothing you should worry about.\n",
    "            rnn_type (str): Either \"RNN\", \"LSTM\" or \"GRU\". Defines what kind of a layer should be used.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        vocab_size = embedding_matrix.shape[0]\n",
    "        embedding_dim = embedding_matrix.shape[1]\n",
    "\n",
    "        # Construct embedding layer and initialize with given embedding matrix. Do not modify this code.\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=vocab_size, embedding_dim=embedding_dim, padding_idx=0\n",
    "        )\n",
    "        self.embedding.weight.data = embedding_matrix\n",
    "\n",
    "        hidden_size = 64\n",
    "        # Define recurrent layer\n",
    "        if rnn_type == 'RNN':\n",
    "            self.rnn = nn.RNN(input_size=embedding_dim, hidden_size=hidden_size, batch_first=True)\n",
    "        elif rnn_type == 'LSTM':\n",
    "            self.rnn = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, batch_first=True)\n",
    "        elif rnn_type == 'GRU':\n",
    "            self.rnn = nn.GRU(input_size=embedding_dim, hidden_size=hidden_size, batch_first=True)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid RNN type '{rnn_type}'. Must be one of 'RNN', 'LSTM', or 'GRU'.\")\n",
    "\n",
    "        # Define output layer\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "        # Define activation function\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Takes in a batch of data of shape (N, max_sequence_length). Returns a tensor of shape (N, 1), where each\n",
    "        element corresponds to the prediction for the corresponding sequence.\n",
    "        \"\"\"\n",
    "        # convert to LongTensor\n",
    "        # Embedding input sequences\n",
    "        embedded = self.embedding(inputs.long())\n",
    "\n",
    "        # Pass through recurrent layer\n",
    "        output, _ = self.rnn(embedded)\n",
    "\n",
    "        # transform the last hidden state of the recurrent layer to a shape\n",
    "        logits = self.fc(output[:, -1, :])\n",
    "\n",
    "        # Activation function\n",
    "        output = self.sigmoid(logits)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def loss(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Computes the binary cross-entropy loss.\n",
    "        \"\"\"\n",
    "        # Calculate binary cross-entropy loss\n",
    "        loss_fn = nn.BCELoss()\n",
    "        loss = loss_fn(logits, targets)\n",
    "        return loss\n",
    "\n",
    "    def accuracy(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Computes the accuracy, i.e number of correct predictions / N.\n",
    "        \"\"\"\n",
    "        # Predictions\n",
    "        predictions = (logits > 0.5).float()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        correct = (predictions == targets).float().sum()\n",
    "        total = targets.size(0)\n",
    "        accuracy = correct / total\n",
    "\n",
    "        return accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Define hyper-parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_parameters() -> Dict:\n",
    "    \"\"\"Returns parameters for training a model. Is have 4 entries, with these specific keys:\n",
    "\n",
    "    {\n",
    "        \"TRAINING_BATCH_SIZE\": TRAINING_BATCH_SIZE,  # type: int\n",
    "        \"VAL_BATCH_SIZE\": VAL_BATCH_SIZE,  # type: int\n",
    "        \"NUM_EPOCHS\": NUM_EPOCHS,  # type: int\n",
    "        \"LEARNING_RATE\": LEARNING_RATE,  # type: float\n",
    "    }\n",
    "\n",
    "    Returns:\n",
    "        Dict: Dictionary, as described above.\n",
    "            (Feel free to copy dict above, and define TRAINING_BATCH_SIZE and LEARNING_RATE)\n",
    "    \"\"\"\n",
    "    # Batch size for validation, this only affects performance.\n",
    "    VAL_BATCH_SIZE = 128\n",
    "\n",
    "    # Training parameters\n",
    "    NUM_EPOCHS = 16\n",
    "    params = {\n",
    "        \"TRAINING_BATCH_SIZE\": 64,\n",
    "        \"VAL_BATCH_SIZE\":VAL_BATCH_SIZE,\n",
    "        \"NUM_EPOCHS\": NUM_EPOCHS,\n",
    "        \"LEARNING_RATE\": 1e-4\n",
    "    }\n",
    "    return params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_dataset = SST2Dataset(\"./data/SST-2/train.tsv\")\n",
    "val_dataset = SST2Dataset(\"./data/SST-2/dev.tsv\", train_dataset.vocab, train_dataset.reverse_vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train different models in SST-2 datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "def train():\n",
    "    # Get parameters from problems\n",
    "    params = get_parameters()\n",
    "    TRAINING_BATCH_SIZE = params[\"TRAINING_BATCH_SIZE\"]\n",
    "    NUM_EPOCHS = params[\"NUM_EPOCHS\"]\n",
    "    LEARNING_RATE = params[\"LEARNING_RATE\"]\n",
    "    VAL_BATCH_SIZE = params[\"VAL_BATCH_SIZE\"]\n",
    "\n",
    "    # Create data loaders for creating and iterating over batches\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=TRAINING_BATCH_SIZE,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=VAL_BATCH_SIZE, collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "\n",
    "    # Print out some random examples from the data\n",
    "    print(\"Data examples:\")\n",
    "    random_indices = torch.randperm(len(train_dataset))[:8].tolist()\n",
    "    for index in random_indices:\n",
    "        sequence_indices, label = (\n",
    "            train_dataset.sentences[index],\n",
    "            train_dataset.labels[index],\n",
    "        )\n",
    "        sentiment = \"Positive\" if label == 1 else \"Negative\"\n",
    "        sequence = train_dataset.indices_to_tokens(sequence_indices)\n",
    "        print(f\"Sentiment: {sentiment}. Sentence: {sequence}\")\n",
    "    print()\n",
    "\n",
    "    embedding_matrix = load_embedding_matrix(train_dataset.vocab)\n",
    "\n",
    "    for model_type in [\"LSTM\", \"RNN\", \"GRU\"]:\n",
    "        model = RNNBinaryClassificationModel(embedding_matrix.clone(), model_type).to(\n",
    "            DEVICE\n",
    "        )\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            # Total loss across train data\n",
    "            train_loss = 0.0\n",
    "            # Total number of correctly predicted training labels\n",
    "            train_correct = 0\n",
    "            # Total number of training sequences processed\n",
    "            train_seqs = 0\n",
    "\n",
    "            print(f\"Model Type: {model_type} Epoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "            tqdm_train_loader = tqdm(train_loader, leave=False)\n",
    "\n",
    "            model.train()\n",
    "            for batch_idx, (sentences_batch, labels_batch) in enumerate(\n",
    "                tqdm_train_loader\n",
    "            ):\n",
    "                sentences_batch, labels_batch = (\n",
    "                    sentences_batch.to(DEVICE),\n",
    "                    labels_batch.to(DEVICE),\n",
    "                )\n",
    "\n",
    "                # Make predictions\n",
    "                logits = model(sentences_batch)\n",
    "\n",
    "                # Compute loss and number of correct predictions\n",
    "                loss = model.loss(logits, labels_batch)\n",
    "                correct = model.accuracy(logits, labels_batch).item() * len(logits)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Accumulate metrics and update status\n",
    "                train_loss += loss.item()\n",
    "                train_correct += correct\n",
    "                train_seqs += len(sentences_batch)\n",
    "                tqdm_train_loader.set_description_str(\n",
    "                    f\"[Loss]: {train_loss / (batch_idx + 1):.4f} [Acc]: {train_correct / train_seqs:.4f}\"\n",
    "                )\n",
    "            tqdm_train_loader.close()\n",
    "            print()\n",
    "\n",
    "            avg_train_loss = train_loss / len(tqdm_train_loader)\n",
    "            train_accuracy = train_correct / train_seqs\n",
    "            print(\n",
    "                f\"\\t[Training Loss]: {avg_train_loss:.4f} [Training Accuracy]: {train_accuracy:.4f}\"\n",
    "            )\n",
    "\n",
    "            # Total loss across validation data\n",
    "            val_loss = 0.0\n",
    "            # Total number of correctly predicted validation labels\n",
    "            val_correct = 0\n",
    "            # Total number of validation sequences processed\n",
    "            val_seqs = 0\n",
    "\n",
    "            tqdm_val_loader = tqdm(val_loader, leave=False)\n",
    "\n",
    "            model.eval()\n",
    "            for batch_idx, (sentences_batch, labels_batch) in enumerate(\n",
    "                tqdm_val_loader\n",
    "            ):\n",
    "                sentences_batch, labels_batch = (\n",
    "                    sentences_batch.to(DEVICE),\n",
    "                    labels_batch.to(DEVICE),\n",
    "                )\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    # Make predictions\n",
    "                    logits = model(sentences_batch)\n",
    "\n",
    "                    # Compute loss and number of correct predictions and accumulate metrics and update status\n",
    "                    val_loss += model.loss(logits, labels_batch).item()\n",
    "                    val_correct += model.accuracy(logits, labels_batch).item() * len(\n",
    "                        logits\n",
    "                    )\n",
    "                    val_seqs += len(sentences_batch)\n",
    "                    tqdm_val_loader.set_description_str(\n",
    "                        f\"[Loss]: {val_loss / (batch_idx + 1):.4f} [Acc]: {val_correct / val_seqs:.4f}\"\n",
    "                    )\n",
    "            tqdm_val_loader.close()\n",
    "            print()\n",
    "\n",
    "            avg_val_loss = val_loss / len(tqdm_val_loader)\n",
    "            val_accuracy = val_correct / val_seqs\n",
    "            print(\n",
    "                f\"\\t[Validation Loss]: {avg_val_loss:.4f} [Validation Accuracy]: {val_accuracy:.4f}\"\n",
    "            )\n",
    "\n",
    "        # Due to the lack of labels in the SST-2 test set, it is not possible to predict test accuracy\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data examples:\n",
      "Sentiment: Negative. Sentence: hell-bent\n",
      "Sentiment: Positive. Sentence: most entertaining moments\n",
      "Sentiment: Positive. Sentence: rising above similar fare\n",
      "Sentiment: Positive. Sentence: raunchy and frequently hilarious\n",
      "Sentiment: Negative. Sentence: as a seven rip-off\n",
      "Sentiment: Negative. Sentence: chafing\n",
      "Sentiment: Negative. Sentence: fails to portray its literarily talented and notorious subject as anything much more than a dirty old man .\n",
      "Sentiment: Positive. Sentence: enter and accept another world\n",
      "\n",
      "Model Type: LSTM Epoch 1/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.6869 [Training Accuracy]: 0.5569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.6988 [Validation Accuracy]: 0.5103\n",
      "Model Type: LSTM Epoch 2/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.5649 [Training Accuracy]: 0.7096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.5942 [Validation Accuracy]: 0.7397\n",
      "Model Type: LSTM Epoch 3/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.4417 [Training Accuracy]: 0.8057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.5453 [Validation Accuracy]: 0.7638\n",
      "Model Type: LSTM Epoch 4/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.3878 [Training Accuracy]: 0.8358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.5371 [Validation Accuracy]: 0.7718\n",
      "Model Type: LSTM Epoch 5/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.3498 [Training Accuracy]: 0.8570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.5117 [Validation Accuracy]: 0.7798\n",
      "Model Type: LSTM Epoch 6/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.3167 [Training Accuracy]: 0.8736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.5098 [Validation Accuracy]: 0.7867\n",
      "Model Type: LSTM Epoch 7/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.2884 [Training Accuracy]: 0.8875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.5160 [Validation Accuracy]: 0.7936\n",
      "Model Type: LSTM Epoch 8/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.2637 [Training Accuracy]: 0.8994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.5457 [Validation Accuracy]: 0.7936\n",
      "Model Type: LSTM Epoch 9/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.2429 [Training Accuracy]: 0.9093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.4981 [Validation Accuracy]: 0.8016\n",
      "Model Type: LSTM Epoch 10/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.2234 [Training Accuracy]: 0.9193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.5787 [Validation Accuracy]: 0.8039\n",
      "Model Type: LSTM Epoch 11/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.2082 [Training Accuracy]: 0.9253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.5653 [Validation Accuracy]: 0.7993\n",
      "Model Type: LSTM Epoch 12/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.1949 [Training Accuracy]: 0.9308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.5812 [Validation Accuracy]: 0.8050\n",
      "Model Type: LSTM Epoch 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.1824 [Training Accuracy]: 0.9359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.6276 [Validation Accuracy]: 0.8005\n",
      "Model Type: LSTM Epoch 14/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.1714 [Training Accuracy]: 0.9407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.7016 [Validation Accuracy]: 0.7844\n",
      "Model Type: LSTM Epoch 15/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.1633 [Training Accuracy]: 0.9431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.6524 [Validation Accuracy]: 0.7936\n",
      "Model Type: LSTM Epoch 16/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.1554 [Training Accuracy]: 0.9472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.7501 [Validation Accuracy]: 0.7787\n",
      "Model Type: RNN Epoch 1/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.6866 [Training Accuracy]: 0.5579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.6984 [Validation Accuracy]: 0.5092\n",
      "Model Type: RNN Epoch 2/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.6862 [Training Accuracy]: 0.5584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.6992 [Validation Accuracy]: 0.5092\n",
      "Model Type: RNN Epoch 3/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.6566 [Training Accuracy]: 0.6195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.7407 [Validation Accuracy]: 0.5780\n",
      "Model Type: RNN Epoch 4/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.6223 [Training Accuracy]: 0.6881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.7028 [Validation Accuracy]: 0.5665\n",
      "Model Type: RNN Epoch 5/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.6358 [Training Accuracy]: 0.6615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.6940 [Validation Accuracy]: 0.5917\n",
      "Model Type: RNN Epoch 6/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.6197 [Training Accuracy]: 0.6872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.6808 [Validation Accuracy]: 0.5872\n",
      "Model Type: RNN Epoch 7/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.6585 [Training Accuracy]: 0.6069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.6573 [Validation Accuracy]: 0.6227\n",
      "Model Type: RNN Epoch 8/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.6072 [Training Accuracy]: 0.6802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.6667 [Validation Accuracy]: 0.6491\n",
      "Model Type: RNN Epoch 9/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.6159 [Training Accuracy]: 0.6488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.6661 [Validation Accuracy]: 0.6216\n",
      "Model Type: RNN Epoch 10/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.6200 [Training Accuracy]: 0.6217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.6882 [Validation Accuracy]: 0.6422\n",
      "Model Type: RNN Epoch 11/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.6187 [Training Accuracy]: 0.6257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.6834 [Validation Accuracy]: 0.6261\n",
      "Model Type: RNN Epoch 12/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.6122 [Training Accuracy]: 0.6728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.7458 [Validation Accuracy]: 0.6112\n",
      "Model Type: RNN Epoch 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.6146 [Training Accuracy]: 0.6502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.6699 [Validation Accuracy]: 0.6353\n",
      "Model Type: RNN Epoch 14/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.6040 [Training Accuracy]: 0.6489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.6594 [Validation Accuracy]: 0.5872\n",
      "Model Type: RNN Epoch 15/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.6197 [Training Accuracy]: 0.6053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.6567 [Validation Accuracy]: 0.6078\n",
      "Model Type: RNN Epoch 16/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.6248 [Training Accuracy]: 0.6889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.6966 [Validation Accuracy]: 0.6491\n",
      "Model Type: GRU Epoch 1/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.6867 [Training Accuracy]: 0.5579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.6980 [Validation Accuracy]: 0.5103\n",
      "Model Type: GRU Epoch 2/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.5775 [Training Accuracy]: 0.6808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.5836 [Validation Accuracy]: 0.7351\n",
      "Model Type: GRU Epoch 3/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.4039 [Training Accuracy]: 0.8258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.5135 [Validation Accuracy]: 0.7661\n",
      "Model Type: GRU Epoch 4/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.3518 [Training Accuracy]: 0.8546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.5070 [Validation Accuracy]: 0.7844\n",
      "Model Type: GRU Epoch 5/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.3143 [Training Accuracy]: 0.8746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.4727 [Validation Accuracy]: 0.7936\n",
      "Model Type: GRU Epoch 6/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.2803 [Training Accuracy]: 0.8892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.4708 [Validation Accuracy]: 0.7947\n",
      "Model Type: GRU Epoch 7/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.2532 [Training Accuracy]: 0.9031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.5154 [Validation Accuracy]: 0.7936\n",
      "Model Type: GRU Epoch 8/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.2307 [Training Accuracy]: 0.9137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.5461 [Validation Accuracy]: 0.7970\n",
      "Model Type: GRU Epoch 9/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.2129 [Training Accuracy]: 0.9214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.5368 [Validation Accuracy]: 0.8073\n",
      "Model Type: GRU Epoch 10/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.1974 [Training Accuracy]: 0.9285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.5644 [Validation Accuracy]: 0.8050\n",
      "Model Type: GRU Epoch 11/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.1857 [Training Accuracy]: 0.9339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.5934 [Validation Accuracy]: 0.8016\n",
      "Model Type: GRU Epoch 12/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.1748 [Training Accuracy]: 0.9378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.6404 [Validation Accuracy]: 0.8016\n",
      "Model Type: GRU Epoch 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.1641 [Training Accuracy]: 0.9426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.6156 [Validation Accuracy]: 0.8073\n",
      "Model Type: GRU Epoch 14/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.1558 [Training Accuracy]: 0.9450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.6348 [Validation Accuracy]: 0.8016\n",
      "Model Type: GRU Epoch 15/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.1488 [Training Accuracy]: 0.9476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.6184 [Validation Accuracy]: 0.8039\n",
      "Model Type: GRU Epoch 16/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Training Loss]: 0.1415 [Training Accuracy]: 0.9498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Validation Loss]: 0.7153 [Validation Accuracy]: 0.8108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Due to the lack of labels in the SST-2 test set, it is not possible to predict test accuracy.\n",
    "The best validation accuracy in different models as follow:\n",
    "\n",
    "| Model | Best Validation Accuracy |\n",
    "| :---: |:------------------------:|\n",
    "|  RNN  |          68.81%          |\n",
    "|  GRU  |          81.08%          |\n",
    "| LSTM  |          80.50%          |"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}